{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T17:47:25.165033Z","iopub.status.busy":"2024-02-04T17:47:25.164640Z","iopub.status.idle":"2024-02-04T17:47:59.563949Z","shell.execute_reply":"2024-02-04T17:47:59.562393Z","shell.execute_reply.started":"2024-02-04T17:47:25.165002Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: peft in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (0.7.1)\n","Requirement already satisfied: trl in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (0.7.10)\n","Requirement already satisfied: accelerate in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (0.25.0)\n","Requirement already satisfied: bitsandbytes in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (0.42.0)\n","Requirement already satisfied: numpy>=1.17 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (1.26.3)\n","Requirement already satisfied: packaging>=20.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (23.2)\n","Requirement already satisfied: psutil in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (5.9.7)\n","Requirement already satisfied: pyyaml in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (2.1.2)\n","Requirement already satisfied: transformers in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (4.38.0.dev0)\n","Requirement already satisfied: tqdm in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (4.66.1)\n","Requirement already satisfied: safetensors in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (0.4.1)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from peft) (0.20.2)\n","Requirement already satisfied: datasets in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from trl) (2.16.1)\n","Requirement already satisfied: tyro>=0.5.11 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from trl) (0.6.6)\n","Requirement already satisfied: scipy in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from bitsandbytes) (1.10.1)\n","Requirement already satisfied: filelock in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n","Requirement already satisfied: requests in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\n","Requirement already satisfied: sympy in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n","Requirement already satisfied: networkx in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\n","Requirement already satisfied: jinja2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from transformers->peft) (0.15.0)\n","Requirement already satisfied: docstring-parser>=0.14.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\n","Requirement already satisfied: rich>=11.1.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\n","Requirement already satisfied: shtab>=1.5.6 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.6.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (0.3.7)\n","Requirement already satisfied: pandas in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (2.1.4)\n","Requirement already satisfied: xxhash in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\n","Requirement already satisfied: multiprocess in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (0.70.15)\n","Requirement already satisfied: aiohttp in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\n","Requirement already satisfied: attrs>=17.3.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2023.11.17)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from pandas->datasets->trl) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\n","Requirement already satisfied: mpmath>=0.19 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n","Requirement already satisfied: datasets in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (2.16.1)\n","Requirement already satisfied: filelock in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (3.13.1)\n","Requirement already satisfied: numpy>=1.17 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (1.26.3)\n","Requirement already satisfied: pyarrow>=8.0.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (2.1.4)\n","Requirement already satisfied: requests>=2.19.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n","Requirement already satisfied: aiohttp in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.19.4 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (0.20.2)\n","Requirement already satisfied: packaging in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"]}],"source":["!pip install peft trl accelerate bitsandbytes\n","!pip install -U datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-04T17:47:59.566435Z","iopub.status.busy":"2024-02-04T17:47:59.566090Z","iopub.status.idle":"2024-02-04T17:48:23.873060Z","shell.execute_reply":"2024-02-04T17:48:23.872068Z","shell.execute_reply.started":"2024-02-04T17:47:59.566406Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import torch\n","import json\n","from datasets import load_dataset, Dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import LoraConfig, PeftModel\n","from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n","import json\n","from os import listdir, makedirs\n","from os.path import isfile, join, splitext, exists\n","\n","# Assume the data set is in the below subfolder\n","inputDataPrefix = \"data/\""]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T17:48:23.875149Z","iopub.status.busy":"2024-02-04T17:48:23.874708Z","iopub.status.idle":"2024-02-04T17:48:23.892055Z","shell.execute_reply":"2024-02-04T17:48:23.891160Z","shell.execute_reply.started":"2024-02-04T17:48:23.875109Z"},"trusted":true},"outputs":[],"source":["# Loads the samples in the train, validation, or test set\n","def loadMOROCODataSamples(subsetName):\n","# Copyright for function (C) 2018  Andrei M. Butnaru, Radu Tudor Ionescu\n","    inputSamplesFilePath = (inputDataPrefix + \"%s/samples.txt\") % (subsetName)\n","    inputDialectLabelsFilePath = (inputDataPrefix + \"%s/dialect_labels.txt\") % (subsetName)\n","    inputCategoryLabelsFilePath = (inputDataPrefix + \"%s/category_labels.txt\") % (subsetName)\n","    \n","    IDs = []\n","    samples = []\n","    dialectLabels = []\n","    categoryLabels = []\n","    \n","    # Loading the data samples\n","    inputSamplesFile = open(inputSamplesFilePath, 'r')\n","    sampleRows = inputSamplesFile.readlines()\n","    inputSamplesFile.close()\n","\n","    for row in sampleRows:\n","        components = row.split(\"\\t\")\n","        IDs += [components[0]]\n","        samples += [\" \".join(components[1:])]\n","\n","    # Loading the dialect labels\n","    inputDialectLabelsFile = open(inputDialectLabelsFilePath, 'r')\n","    dialectRows = inputDialectLabelsFile.readlines()\n","    inputDialectLabelsFile.close()\n","    \n","    for row in dialectRows:\n","        components = row.split(\"\\t\")\n","        dialectLabels += [int(components[1])]\n","    \n","    # Loading the category labels\n","    inputCategoryLabelsFile = open(inputCategoryLabelsFilePath, 'r')\n","    categoryRows = inputCategoryLabelsFile.readlines()\n","    inputCategoryLabelsFile.close()\n","    \n","    for row in categoryRows:\n","        components = row.split(\"\\t\")\n","        categoryLabels += [int(components[1])]\n","\n","    # IDs[i] is the ID of the sample samples[i] with the dialect label dialectLabels[i] and the category label categoryLabels[i]\n","    return IDs, samples, dialectLabels, categoryLabels\n","\n","def build_instruction_set(task_ids, task_samples, task_labels, format=\"mistral\", task=\"dialect\"):\n","    \"\"\"\n","    Build an instruction set for a specified task in a given format.\n","\n","    Parameters:\n","    - task_ids (list): ids from MOROCO\n","    - task_samples (list): text samples\n","    - task_labels (list): labels for the given task\n","    - format (str, optional): model to be used, for the moment Mistral\n","    - task (str, optional): unused, maybe to switch to other Vardial tasks\n","\n","    Returns:\n","    - instruction_set (str): json set with raw and instruction texts\n","    \"\"\"\n","\n","    json_set = []\n","    for id, sample, label in zip(task_ids, task_samples, task_labels):\n","        instruction = f\"[INST] O să primești un fragment dintr-un articol de știri scris în limba română. Trebuie să îl clasifici în dialectul standard al limbii române, sau în dialectul moldovenesc, folosit în Republica Moldova. Numele de persoane sau de locuri geografice au fost schimbate în \\\"$NE#\\\", ca să fie împiedicată folosirea de denumiri specifice pentru identificare, în loc de proprietăți lingvistice.\\nFragmentul este acesta:\\\"{sample}\\\"\\n Alege unul dintre cele doua dialecte pentru clasificare:\\n1. dialectul moldovenesc\\n2. dialectul standard\\n[/INST]\\n Dialectul din fragment este {label}.\"\n","\n","        json_set.append({\n","            'id': id,\n","            'raw_sample': sample,\n","            'instr_sample': instruction,\n","            'dialect': label\n","        })\n","    \n","    return json_set\n","\n","def get_set(split, format=\"mistral\", task=\"dialect\"):\n","    task_ids, task_samples, task_dialect, task_category = loadMOROCODataSamples(split)\n","    return build_instruction_set(task_ids, task_samples, task_dialect, format=format, task=task)\n","\n","def write_set(split, out_root, format=\"mistral\", task=\"dialect\"):\n","    task_ids, task_samples, task_dialect, task_category = loadMOROCODataSamples(split)\n","    task0_set = build_instruction_set(task_ids, task_samples, task_dialect, format=format, task=task)\n","    task0_fp =  os.path.join(out_root, f'{split}_model={format}_task={task}.jsonl')\n","    with open(task0_fp, 'w') as f:\n","        for obj in task0_set:\n","            json.dump(obj, f)\n","            f.write('\\n')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T17:48:23.894761Z","iopub.status.busy":"2024-02-04T17:48:23.894354Z","iopub.status.idle":"2024-02-04T17:48:25.203954Z","shell.execute_reply":"2024-02-04T17:48:25.202953Z","shell.execute_reply.started":"2024-02-04T17:48:23.894730Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'raw_sample', 'instr_sample', 'dialect'],\n","        num_rows: 21719\n","    })\n","})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# json_dataset = get_set(\"train\")\n","# dataset = []\n","# for obj in json_dataset:\n","#     instr = obj[\"instr_sample\"]\n","#     dataset.append(instr)\n","# dataset = Dataset.from_dict({\"text\": dataset})\n","dataset = load_dataset('json', data_files='data/train_model=mistral_task=dialect.jsonl')\n","dataset.shuffle(seed=1337)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T17:48:25.205404Z","iopub.status.busy":"2024-02-04T17:48:25.205103Z","iopub.status.idle":"2024-02-04T17:48:25.209793Z","shell.execute_reply":"2024-02-04T17:48:25.208809Z","shell.execute_reply.started":"2024-02-04T17:48:25.205379Z"},"trusted":true},"outputs":[],"source":["# The model that you want to train from the Hugging Face hub\n","model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","\n","# Fine-tuned model name\n","new_model = \"mistral-finetuned\"\n","\n","output_dir = \"./results\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-04T17:48:25.211682Z","iopub.status.busy":"2024-02-04T17:48:25.211162Z","iopub.status.idle":"2024-02-04T17:54:54.062378Z","shell.execute_reply":"2024-02-04T17:54:54.060663Z","shell.execute_reply.started":"2024-02-04T17:48:25.211652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["================================================================================\n","Your GPU supports bfloat16: accelerate training with bf16=True\n","================================================================================\n"]},{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n","Map: 100%|██████████| 21719/21719 [00:04<00:00, 5022.72 examples/s]\n","Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtantarudragos\u001b[0m (\u001b[33mdtant\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.16.2"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/dragos/lang_ident/wandb/run-20240204_222841-jgfppe3d</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/dtant/huggingface/runs/jgfppe3d' target=\"_blank\">magic-sponge-131</a></strong> to <a href='https://wandb.ai/dtant/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/dtant/huggingface' target=\"_blank\">https://wandb.ai/dtant/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/dtant/huggingface/runs/jgfppe3d' target=\"_blank\">https://wandb.ai/dtant/huggingface/runs/jgfppe3d</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/339 [00:00<?, ?it/s]/home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages/trl/trainer/utils.py:129: UserWarning: Could not find response key `[6766, 13693, 7021, 28705]` in the following instance: <s> [INST] O să primești un fragment dintr-un articol de știri scris în limba română. Trebuie să îl clasifici în dialectul standard al limbii române, sau în dialectul moldovenesc, folosit în Republica Moldova. Numele de persoane sau de locuri geografice au fost schimbate în \"$NE#\", ca să fie împiedicată folosirea de denumiri specifice pentru identificare, în loc de proprietăți lingvistice.\n","Fragmentul este acesta:\"Decizia lui $NE$ a înfuriat aliați puternici ai $NE$  propriul partid republican şi a provocat o undă de şoc pe $NE$ $NE$ unde indicele $NE$ a pierdut 420 de puncte . Cele mai afectate țări sunt $NE$ $NE$ şi $NE$ de $NE$ şi nu $NE$ relatează $NE$ . Cu riscul de a provoca un război comercial cu principalii săi parteneri comerciali şi în primul rând cu $NE$ $NE$ a anunţat că va promulga săptămâna viitoare taxe vamale mari pentru importurile de oţel şi aluminiu . Vor fi taxe de 25% pentru oţel şi 10% pentru aluminiu, a anunţat $NE$ . Fără să dea prea multe detalii, preşedintele a subliniat că importurile ieftine \"distrug industria şi locurile de muncă  din $NE$ $NE$ . Condiţiile suportate de noi în ultimele decenii sunt pur şi simplu ruşinoase, consideră preşedintele american . Într - o reacţie imediată, congresmeni republicani au avertizat tăios ca o asemenea măsură ar fi resimţitaă tot de americanul de rând în preţul bunurilor de consum, de la conserve până la maşini şi bilete de avion . Ca să - şi ducă la bun sfârşit intenţia, $NE$ s - ar folosi de o lege comercială puţin cunoscută, din 1962, aplicabilă în situaţia în care \"importurile de oţel şi aluminiu afectează securitatea naţională\" . $NE$ va contracara corespunzător pentru a - şi proteja muncitorii şi industria . Şi, să nu uităm că, de fapt, $NE$ au un surplus comercial cu noi de 2 miliarde . Canada cumpăra mai mult oţel american decât orice altă ţară din lume . Aşa că orice sugestie că oţelul canadian ar reprezenta o ameninţare pentru securitatea naţională americană este în mod vădit înşelătoare, a anunţat $NE$ - $NE$ $NE$ ministrul canadian al $NE$ $NE$ . Nu credem că importurile americane de oţel şi aluminiu din $NE$ stat aliat al $NE$ afectează securitatea naţională americană . Sper să transmit acest mesaj şi americanilor când voi avea ocazia, susţine $NE$ $NE$ $NE$ japonez al $NE$ . Şi $NE$ al doilea partener comercial al $NE$ ar putea percepe anunţul lui $NE$ drept o declaraţie de război comercial . Nu vreau să vorbesc de un război comercial, dar de obicei războaiele încep cu o primă bătălie, iar asta e una majoră, a declarat $NE$ $NE$ fostul secretarul american pentru comerţ . China nu este totuşi principalul furnizor de oţel al americanilor . $NE$ şi $NE$ de $NE$ sunt cei mai importanţi exportatori de oţel către $NE$ $NE$ . $NE$ ar putea introduce tarife \"de protecţie\" la importurile de oţel şi aluminiu, ca răspuns la decizia $NE$ va lua în considerare propriile sale tarife \"de protecţie\" la importurile de oţel şi aluminiu, ca răspuns la decizia preşedintele $NE$ $NE$ a afirmat comisarul european pentru $NE$ $NE$ $NE$ într - un interviu acordat publicaţiei britanice $NE$ $NE$ citat de $NE$ . Oficialii de la $NE$ aşteaptă anunţul oficial privind tarifele impuse de $NE$ înainte de a lua o decizie, a precizat $NE$ $NE$ adăugând că $NE$ nu are altă opţiune decât să răspundă, aşa cum au avertizat şi alte state afectate, cum ar fi $NE$ şi $NE$ . Pieţele bursiere globale au reacţionat vineri, acţiunile din $NE$ şi $NE$ deschizând în scădere, investitorii vânzând masiv titluri ale producătorilor şi exportatorilor de aluminiu şi oţel . $NE$ susţine că decizia administraţiei $NE$ de a folosi reglementările legate de securitatea naţională pentru a impune tarife reprezintă un motiv serios de îngrijorare . Decizia riscă să submineze $NE$ $NE$ a $NE$ ( $NE$ ) ş va provoca alte state să răspundă cu măsuri similare, a avertizat comisarul european pentru comerţ . Aceasta a adăugat că $NE$ discută deja cu alte ţări pentru a reclama la $NE$ impunerea tarifelor de import de către $NE$ iar forul comunitar este pregătit să adopte imediat măsuri, ţinând cont că un proces la $NE$ poate dura ani de zile . Oficialii europeni sunt îngrijoraţi că tarifele impuse de $NE$ ar putea devia spre $NE$ oţelul care urma să fie exportat în $NE$ ceea ce ar afecta industria europeană a oţelului . De aceea, $NE$ va lansa probabil o investigaţie \"de protecţie\" privind importurile, ceea ce ar putea determina forul comunitar să impună propriile sale tarife la importurile de oţel şi aluminiu, a declarat $NE$ $NE$ . Aceasta a apreciat că decizia $NE$ reprezintă o ameninţare la adresa relaţiilor comerciale transatlantice şi va submina eforturile globale de a rezolva problema supraproducţiei din $NE$ de oţel şi alte metale, care a dus în ultimii ani la scăderea preţurilor . În decembrie, $NE$ $NE$ şi $NE$ au anunţat că vor lucra împreună pentru a combate problema supracapacităţii şi încălcarea drepturilor de proprietate intelectuală . Acum, există dubii privind funcţionarea alianţei, a declarat comisarul european pentru comerţ . Marţi, miniştrii $NE$ din $NE$ au anunţat că vor răspunde cu măsuri de contracarare, dacă $NE$ $NE$ introduc tarife de import la oţel şi aluminiu . Introducerea unor astfel de tarife, o idee lansată de preşedintele $NE$ $NE$ este incompatibilă cu reglementările $NE$ $NE$ a $NE$ ( $NE$ ) şi nu se justifică pe motive legate de siguranţa statului, a afirmat adjunctul ministrului german al $NE$ $NE$ $NE$ . $NE$ a anunţat că pregăteşte, alături de echipa ei, măsurile care ar urma să fie anunţate săptămâna viitoare de $NE$ $NE$ ca răspuns la decizia $NE$ $NE$ fost consilier comercial al This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n","  warnings.warn(\n","/home/dragos/miniforge3/envs/lowrank/lib/python3.10/site-packages/trl/trainer/utils.py:129: UserWarning: Could not find response key `[6766, 13693, 7021, 28705]` in the following instance: <s> [INST] O să primești un fragment dintr-un articol de știri scris în limba română. Trebuie să îl clasifici în dialectul standard al limbii române, sau în dialectul moldovenesc, folosit în Republica Moldova. Numele de persoane sau de locuri geografice au fost schimbate în \"$NE#\", ca să fie împiedicată folosirea de denumiri specifice pentru identificare, în loc de proprietăți lingvistice.\n","Fragmentul este acesta:\"$NE$ se războiește dur cu cei care au contestat - o înainte și în timpul $NE$ de la $NE$ . După ce a ratat calificarea în finală la sol și nu a luat nicio medalie la bârnă, $NE$ le transmite un mesaj extrem de dur celor care o contestă .  \"15 august . . .  $NE$ fost o zi extrem de grea si tensionata pentru mine . . .  $NE$ ce ? Credeți ca mie mi'a fost ușor sau imi este ușor ?  $NE$ ani de munca in spate, nivelul a crescut, gimnastica nu mai e ce era inainte  ? ? Acum ori câștigi cu acrobatică f dificila ori cu artistica făcută perfect .  $NE$ am încercat sa le combin si am greșit pentru ca presiunea a fost extrem de mare . ? Fiind singura gimnasta care a reprezentat $NE$ trebuia sa multumesc intr'un fel sau altul pe toată lumea chiar daca nu mai aveam nimic de dovedit, poate doar mie sa imi mai dovedesc încă o data ca pot !  $NE$ pare rau ca atunci cand mi'am dat seama ca $NE$ a ieșit prost nu am facut si coborârea care a fost pregătită pentru finala$NE$ $NE$ $NE$ ! ! ! $NE$ $NE$ ! ! !  $NE$ zice chiar m'am simțit mai in forma decat la 16 ani .  $NE$ as fi putut daca nu simțeam ca o mana care voia sa ma dea jos de pe aparat toate comentariile si undele negative ca nu meritam sa fiu la $NE$ .  $NE$ dorit prea mult, mi s'a rupt sufletul, am plâns toată noaptea si la un moment dat voiam sa ma opresc si nu puteam, nu mi'a fost ușor sa nu pun la suflet tot ce vedeam sau auzeam in jurul meu si in rețelele de socializare sau presa si nu imi este ușor nici in continuare !  $NE$ avut noroc ca mi'a dat $NE$ un psihic extrem de tare si am reușit sa stau concentrata atat cat am putut .  $NE$ nu aveți impresia ca nu vad tot ce scrieți sau tot ce ziceți pe la spatele meu ( aviz celor din jurul meu ) , doar ca nu am băgat de seama sau v'am lăsat sa va faceți nebunia si sa ma barfiti !  $NE$ fiind de toate rautatile care au inceput de dupa $NE$ am vrut sa fie bine, sa fie bine pentru mine, pentru $NE$ pentru cei care mi'au fost alaturi, care au luptat cu mine zi de zi, care m'au incurajat la fiecare pas, care stiu prin ce am trecut, cate piedici am avut, cate vorbe urate aruncate in mine fara rost !  $NE$ ? Oare la 29 de ani sunt baba, cand sunt \"$NE$ gimnaste in lumea asta trecute de 30 de ani ?  $NE$ e mai greu de stiut fiindca nu toate au rezultate care sa le țină lumea minte ! Urata ?  $NE$ sunt, nu stiu, nu toata lumea e fotomodel, nici nu am fost si nici nu sunt un sportiv stil \"pitzi\" sa nu pot sta fara unghii false, fara par vopsit, gene false sau mai stiu eu ce minunatii de genul, fiindca sunt prea concentrata la ce am de facut !  $NE$ ? Din pacate, aici am sa va spun cu mana pe inima ca multa lume, dupa ce ma cunoaste personal, isi retrage cuvintele , pentru ca de foarte multe ori, chiar daca nu arat, sunt o persoana mai mult decat saritoare, nu port pica, nu port ura, nu imi doresc ca altul sa se loveasca sau sa pățească ceva, întotdeauna am fost acolo atunci cand a fost nevoie de mine, dar asta știu numai acele persoane care imi sunt alături si la bine si la rau, nu persoanele false care acum iti zâmbesc si dupa câteva secunde se întorc cu spatele si te bârfesc, fiindca nu te suporta !  $NE$ ?  $NE$ ca am o masca pusă cand ma antrenez sau cand sunt in concurs dovedește cat de mult imi doresc sa fac ceva, dar persoanele frustrate nu vor vedea niciodată adevarata mea fata, iar cei care ajung sa ma cunoască chiar si pentru prima oară imi spun . . . . . . \" $NE$ crezi ca nu am crezut o secunda ca esti asa cu bun simt si atat de cumsecade ? \" . . . . . . si nu de putine ori am văzut întrebarea \"cand a tras $NE$ echipa dupa ea ? \" $NE$ ia hai sa ne aducem aminte . . . E adevărat ca întotdeauna in spatele meu a mai fost cineva care m - a ajutat ca de exemplu $NE$ $NE$ $NE$ sau $NE$ ! ! Incepând cu anul 2003, oare cine a facut parte din echipa pana in prezent ?  $NE$ rezultatele cele mai bune din 2003 - 2004 ale cui au fost ? In 2005 cine a reprezentat $NE$ si a venit cu medalie de bronz la mondiale cand toată echipa era data afara din lot ? Cine a fost langa fetele din 2006 la europene ?  $NE$ s - a întors in mai 2007 din pauza de 8 luni, ca in 3 luni sa isi revină pentru mondiale si sa ajute intr'un fel sau altul echipa ?  $NE$ in 2011 cine a revenit dupa 4 ani si o intervenție la inima tot pentru a ajuta echipa la $NE$ sa se califice la olimpiada unde am plecata singura, fara $NE$ cu fete fara experiența si mi'am călcat pe orice principiu ca veneam dintr'o echipa campioana olimpică si mi'am asumat din nou un asa zis \"eșec\" : sa ne întoarcem fara medalii de la mondiale ? Si atunci am reușit sa ajut echipa sa vina pe locul 4 ? Oare cine ? ? ? ? Oare in 2012 împreuna cu $NE$ cine a condus echipa sa vina pe locul $NE$ la europene, încercând sa dea exemplu celor mici cum sa fie unite ca si echipa ? Oare la olimpiada, unde toată lumea spunea, inclusiv antrenorii, ca noi nu vom ieși pe podium din cauza ca $NE$ este accidentata, oare cine a tras si cu dinții din nou cu $NE$ pentru echipa ca sa ieșim in primii 3 ? Oare acum, dupa ce nu mai aveam nimic de dovedit, cine a revenit dupa 3 ani de pauza din nou sa încerce sa ajute aceasta echipa care se vedea de la $NE$ din 2014 ca ceva nu funcționează ?  $NE$ ce m'am operat si am tras 5 luni cu dinții de mine cand antrenorii imi spuneau ca fac de fapt fițe si ca nu vreau sa ma duc la recalificări, ca nu ma doare nimic chiar daca plângeam de durere in sala si din ianuar This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n","  warnings.warn(\n"]},{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.66 GiB of which 84.75 MiB is free. Including non-PyTorch memory, this process has 21.38 GiB memory in use. Of the allocated memory 20.88 GiB is allocated by PyTorch, and 197.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 89\u001b[0m\n\u001b[1;32m     74\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SFTTrainer(\n\u001b[1;32m     75\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     76\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mcollator,\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Save trained model\u001b[39;00m\n\u001b[1;32m     92\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(new_model)\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:323\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 323\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/transformers/trainer.py:2768\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2767\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2768\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2771\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/transformers/trainer.py:2791\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2790\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2791\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2792\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2794\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:680\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:668\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_fp32\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:647\u001b[0m, in \u001b[0;36mconvert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_fp16_bf16_tensor\u001b[39m(tensor):\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39mfloat16, torch\u001b[38;5;241m.\u001b[39mbfloat16)\n\u001b[0;32m--> 647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_to_fp32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_fp16_bf16_tensor\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:121\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    111\u001b[0m         data,\n\u001b[1;32m    112\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m         ),\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[0;32m--> 121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[1;32m    123\u001b[0m                 func, v, \u001b[38;5;241m*\u001b[39margs, test_type\u001b[38;5;241m=\u001b[39mtest_type, error_on_other_type\u001b[38;5;241m=\u001b[39merror_on_other_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    124\u001b[0m             )\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:122\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    111\u001b[0m         data,\n\u001b[1;32m    112\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m         ),\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[0;32m--> 122\u001b[0m             k: \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:110\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:84\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:113\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    111\u001b[0m         data,\n\u001b[1;32m    112\u001b[0m         (\n\u001b[0;32m--> 113\u001b[0m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m    117\u001b[0m         ),\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:110\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:84\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:113\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    111\u001b[0m         data,\n\u001b[1;32m    112\u001b[0m         (\n\u001b[0;32m--> 113\u001b[0m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m    117\u001b[0m         ),\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:129\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     )\n","File \u001b[0;32m~/miniforge3/envs/lowrank/lib/python3.10/site-packages/accelerate/utils/operations.py:642\u001b[0m, in \u001b[0;36mconvert_to_fp32.<locals>._convert_to_fp32\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_fp32\u001b[39m(tensor):\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 23.66 GiB of which 84.75 MiB is free. Including non-PyTorch memory, this process has 21.38 GiB memory in use. Of the allocated memory 20.88 GiB is allocated by PyTorch, and 197.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["# Load tokenizer and model with QLoRA configuration\n","compute_dtype = getattr(torch, \"float16\")\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=\"float16\",\n","    bnb_4bit_use_double_quant=False,\n",")\n","\n","# Check GPU compatibility with bfloat16\n","if compute_dtype == torch.float16:\n","    major, _ = torch.cuda.get_device_capability()\n","    if major >= 8:\n","        print(\"=\" * 80)\n","        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n","        print(\"=\" * 80)\n","\n","# Load base model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=bnb_config,\n","    # load_in_8bit=True,\n","    device_map=\"auto\",\n","    attn_implementation = 'flash_attention_2'\n",")\n","# model.config.use_cache = False\n","model.config.pretraining_tp = 1\n","\n","# Load LLaMA tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n","def formatting_prompts_func(example):\n","    output_texts = []\n","    for instr in example['instr_sample']:\n","        output_texts.append(instr)\n","    return output_texts\n","response_format = 'din fragment este '\n","\n","collator = DataCollatorForCompletionOnlyLM(tokenizer.encode(response_format, add_special_tokens = False), tokenizer=tokenizer)\n","# Load LoRA configuration\n","peft_config = LoraConfig(\n","    lora_alpha=256,\n","    lora_dropout=0.1,\n","    r=64,\n","    bias=\"none\",\n","    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\"],\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","# Set training parameters\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,\n","    num_train_epochs=1,\n","    per_device_train_batch_size=1,\n","    gradient_accumulation_steps=64,\n","    optim=\"adamw_torch_fused\",\n","    save_steps=0,\n","    logging_steps=5,\n","    learning_rate=2e-4,\n","    weight_decay=0.001,\n","    fp16=False,\n","    bf16=True,\n","    max_grad_norm=1.,\n","    max_steps=-1,\n","    warmup_ratio=0.03,\n","    group_by_length=True,\n","    lr_scheduler_type=\"cosine\",\n","    # report_to=\"tensorboard\"\n",")\n","\n","# Set supervised fine-tuning parameters\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset['train'],\n","    peft_config=peft_config,\n","    dataset_text_field=\"instr_sample\",\n","    # max_seq_length=None,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    max_seq_length=2200,\n","    packing=False,\n","    formatting_func=formatting_prompts_func,\n","    data_collator=collator,\n",")\n","\n","# Train model\n","trainer.train()\n","\n","# Save trained model\n","trainer.model.save_pretrained(new_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-02-04T17:54:54.063304Z","iopub.status.idle":"2024-02-04T17:54:54.063694Z","shell.execute_reply":"2024-02-04T17:54:54.063546Z","shell.execute_reply.started":"2024-02-04T17:54:54.063531Z"},"trusted":true},"outputs":[],"source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n","    device_map={\"\": 1},\n",")\n","model = PeftModel.from_pretrained(base_model, new_model)\n","model = model.merge_and_unload()\n","\n","# Reload tokenizer to save it\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4398921,"sourceId":7552701,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
